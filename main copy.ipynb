{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code sketch:\n",
    "# 1. small subset of songs, get lyrics / info from spotify / genius api\n",
    "#     turn lyrics coupled w metadata into vector using BERT or something\n",
    "#.    store in Pinecone? FAISS\n",
    "# 2. user input > gpt 4 / langchain to get semantic vector rep. of that\n",
    "#.     compare using cosine sim., closest 10 get suggested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPOTIFY / GENIUS END:\n",
    "#.   (first, parse user input, find vector vs. \"energy\" and other things that could narrow the search)\n",
    "#    pick 100 random songs that work > get their metadata and send to genius > extract lyrics, save as text files\n",
    "#          if no lyrics, reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3006e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGCHAIN:\n",
    "#   turn the lyrics into vectors > store in pinecone\n",
    "#   user input from gpt into langchain > comapre to vector store\n",
    "#   Find top 10 songs in song names > send back to spotify to pull up those songs as playable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42729092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary files\n",
    "from setup import *\n",
    "from spotify_handler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04e74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trackList = [] #empty tracklist array we're gonna fill\n",
    "songNumber = 10000 # number of songs we're gonna sample from randomly\n",
    "pbar = tqdm(total = songNumber) #progress bar init\n",
    "query_offset = 600\n",
    "\n",
    "trackList = build_track_list(songNumber, query_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd9403",
   "metadata": {},
   "source": [
    "while len(trackList) <= songNumber: \n",
    "    ranNum = random.randint(1,600) # make sure the offset is a random one so there's never repeats, and they aren't all super pop. new.\n",
    "    query = get_random_search() #use the function to get a random search on a letter, ie. e% so any song that starts with that letter\n",
    "    track = sp.search(query, limit=1, offset = ranNum, type='track') #query spotify\n",
    "    trackURI = track['tracks']['items'][0]['uri']\n",
    "    trackURI = trackURI.replace('spotify:album:', '')\n",
    "    trackName = track['tracks']['items'][0]['name']\n",
    "    trackArtist = track['tracks']['items'][0]['artists'][0]['name']\n",
    "    audio_features = sp.audio_features(trackURI)\n",
    "    instrumentalness = audio_features[0]['instrumentalness'] #does this have lyrics?\n",
    "    \n",
    "    if instrumentalness <= 0.5: #if no lyrics, reject and get a new one\n",
    "        sleep(0.1)\n",
    "        pbar.update(1)\n",
    "        array = [trackName, trackArtist]\n",
    "        trackList.append(array)\n",
    "\n",
    "        track = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENIUS PART , now we take the song lists and download the lyrics for each one into separate text files for parsing with LangCHAIN:\n",
    "# going to use lyricsgenius which is a python wrapper for GENIUS API\n",
    "genius = Genius(token)\n",
    "\n",
    "\n",
    "genius = lyricsgenius.Genius(\"my_token\")  # replace with your token\n",
    "genius.verbose = False\n",
    "\n",
    "#custom get song lyrics function, with timeout behavior\n",
    "def get_song_lyrics(title, artist, max_retries=5, delay_between_retries=10):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            song = genius.search_song(title=title, artist=artist)\n",
    "            if song is not None:\n",
    "                return song\n",
    "            else:\n",
    "                print(f\"No lyrics found for {title} by {artist}.\")\n",
    "                return None\n",
    "        except Timeout:\n",
    "            if attempt < max_retries - 1:  # it's not the last attempt\n",
    "                print(f\"Timeout occurred when getting lyrics for {title} by {artist}. \"\n",
    "                      f\"Waiting {delay_between_retries} seconds before retrying...\")\n",
    "                time.sleep(delay_between_retries)\n",
    "                continue\n",
    "            else:  # it's the last attempt\n",
    "                print(f\"Still experiencing timeouts after {max_retries} attempts. \"\n",
    "                      f\"Giving up on getting lyrics for {title} by {artist}.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    for char in ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|']:\n",
    "        name = name.replace(char, '_')\n",
    "    return name\n",
    "\n",
    "for i in tqdm(trackList):\n",
    "    title = sanitize_filename(i[0])\n",
    "    artist = sanitize_filename(i[1])\n",
    "    song = get_song_lyrics(title, artist,5,10)\n",
    "    if song != None and \"[Verse\" in song.lyrics:\n",
    "        lyrics = song.lyrics\n",
    "        with open('lyrics/%s_%s.txt'%(title,artist), 'w') as f:\n",
    "            f.write(lyrics)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LANGCHAIN TIME\n",
    "# here gonna take each lyric file and summarize it / vectorize it and store in pinecone\n",
    "# initialize langchain / openAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = openai_api_key)\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "docs=[]\n",
    "summary = []\n",
    "\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith(\".txt\"):  # check if the file is a .txt file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # now you can do something with the file\n",
    "        loader = TextLoader(file_path)\n",
    "        doc = loader.load()\n",
    "        docs.append(doc)\n",
    "for i in tqdm(docs):\n",
    "    summary.append(chain.run(i))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment='asia-northeast1-gcp'\n",
    ")\n",
    "\n",
    "index_name=\"spotifysemantic\"\n",
    "\n",
    "for i in tqdm(docs):\n",
    "    docsearch=Pinecone.from_documents(i, embeddings, index_name=index_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab09df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "query = \"songs for the best day of my life\"\n",
    "ans = docsearch.similarity_search(query)\n",
    "\n",
    "for i in ans:\n",
    "    print(i.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eac965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
